---
title: "Week 3 - Homework"
author: "Aman Arora - amana4@illinois.edu"
date: ''
output:
  html_document: 
    theme: readable
    toc: yes  
  pdf_document: default
urlcolor: cyan
---

## Exercise 1 (Using `lm` for Inference)

For this exercise we will use the `cats` dataset from the `MASS` package. You should use `?cats` to learn about the background of this dataset.

**(a)** Fit the following simple linear regression model in `R`. Use heart weight as the response and body weight as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `cat_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.05$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

**Solution**:
```{r}
library("MASS")
cat_model = lm(Hwt~Bwt, data = cats)
result = summary(cat_model)
```

* The null hypothesis is $H_0:\beta1 = 0$ i.e there is no relationship  between cat's heart weight and body weight. Alternative hypothesis is  $H1:\beta1 \ne 0$ i.e there is a relationship  between cat's heart weight and body weight

* The t statistic is: `r result$coefficients[2,3]` 

* The p value is 2.2e-16

* At $\alpha = 0.05$  we can reject the NULL hypothesis. 

* Rejection of NULL hypothesis indicates there is significant evidence for a relationship between between cat's heart weight and body weight


**(b)** Calculate a 95% confidence interval for $\beta_1$. Give an interpretation of the interval in the context of the problem.

```{r}
intervals = confint(cat_model, level = .95)

```
95% confidence interval for $\beta_1$ is: (`r intervals[2,1]`, `r intervals[2,2]`). The interpretation here is we are 99% confident that the true mean of rate of change of heart weight with body weight is in this interval.


**(c)** Calculate a 90% confidence interval for $\beta_0$. Give an interpretation of the interval in the context of the problem.

```{r}
intervals = confint(cat_model, level = .9)
```

90% confidence interval for $\beta_0$ is: (`r intervals[1,1]`, `r intervals[1,2]`).The interpretation here is we are 90% confident that the true mean of rate of change of heart weight with body weight is in this interval.


**(d)** Use a 90% confidence interval to estimate the mean heart weight for body weights of 2.1 and 2.8 kilograms. Which of the two intervals is wider? Why?

```{r}
new_bwt = data.frame(Bwt = c(2.1,2.8))
result = predict(cat_model, newdata = new_bwt, interval = c("confidence"), level =0.9)
result
```

The interval is wider for body weight 2.1 since its farther from mean of body weight hence has greater variance.     


**(e)** Use a 90% prediction interval to predict the heart weight for body weights of 2.8 and 4.2 kilograms.

```{r}

new_bwt = data.frame(Bwt = c(2.8,4.2))
result = predict(cat_model, newdata = new_bwt, interval = c("prediction"), level =0.9)
result

```


**(f)** Create a scatterplot of the data. Add the regression line, 95% confidence bands, and 95% prediction bands.


```{r}

Bwt_grid = seq(min(cats$Bwt), max(cats$Bwt), by = 0.01)

hwt_ci_band = predict(cat_model, newdata = data.frame(Bwt =Bwt_grid ), interval = "confidence",level = .95)

hwt_pi_band = predict(cat_model, newdata = data.frame(Bwt =Bwt_grid ), interval = "prediction",level = .95)

plot(Hwt~Bwt, data = cats, ylim = c(min(hwt_pi_band),max(hwt_pi_band)), main = "Heart Weight vs Body Weight of cats", xlab= "Body Weight(kg)", ylab ="Heart Weight(grams)")

abline(cat_model, col = "red")

lines(Bwt_grid,hwt_ci_band[,"lwr"],col ="blue",lwd = 3, lty = 2)
lines(Bwt_grid,hwt_ci_band[,"upr"],col ="blue",lwd = 3, lty = 2)

lines(Bwt_grid,hwt_pi_band[,"lwr"],col ="blue",lwd = 3, lty = 3)
lines(Bwt_grid,hwt_pi_band[,"upr"],col ="blue",lwd = 3, lty = 3)

```


**(g)** Use a $t$ test to test:

- $H_0: \beta_1 = 4$
- $H_1: \beta_1 \neq 4$

Report the following:

- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.05$

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

```{r}
result  = summary(cat_model)$coefficients

beta_hat_1 = result[2,1]
se = result[2,2]

#Hypothesized Beta1
beta_hyp = 4

t = (beta_hat_1- beta_hyp)/se

p = 2*pt(abs(t), df = nrow(cats) -2,lower.tail = FALSE)

```
* The Value of test statistic is: `r t`
* the p value is:`r p` 
* At $\alpha = 0.05$ we fail to reject $H_0$


```{r}

summary(cat_model)$coefficients
```




***

## Exercise 2 (More `lm` for Inference)

For this exercise we will use the `Ozone` dataset from the `mlbench` package. You should use `?Ozone` to learn about the background of this dataset. You may need to install the `mlbench` package. If you do so, do not include code to install the package in your `R` Markdown document.

For simplicity, we will re-perform the data cleaning done in the previous homework.

```{r}
data(Ozone, package = "mlbench")
Ozone = Ozone[, c(4, 6, 7, 8)]
colnames(Ozone) = c("ozone", "wind", "humidity", "temp")
Ozone = Ozone[complete.cases(Ozone), ]
```

**(a)** Fit the following simple linear regression model in `R`. Use the ozone measurement as the response and wind speed as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `ozone_wind_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

```{r}

wind_model = lm(ozone~wind, data = Ozone)
result = summary(wind_model)

```

* The null hypothesis is $H_0:\beta1 = 0$ i.e there is no relationship  between Ozone and Wind. Alternative hypothesis is  $H1:\beta1 \ne 0$ i.e there is a relationship  between between Ozone reading and Wind

* The t statistic is: `r result$coefficients[2,3]` 

* The p value is 0.8268

* At $\alpha = 0.05$  we fail to reject the NULL hypothesis. 

* There is not enough evidence in data to reject the possibility of no relationship between Ozone readings and wind. 

**(b)** Fit the following simple linear regression model in `R`. Use the ozone measurement as the response and temperature as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `ozone_temp_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

```{r}
temp_model = lm(ozone~temp, data = Ozone)
result = summary(temp_model)
result
```

* The null hypothesis is $H_0:\beta1 = 0$ i.e there is no relationship  between Ozone and temperature. Alternative hypothesis is  $H1:\beta1 \ne 0$ i.e there is a relationship  between between Ozone reading and temperature

* The t statistic is: `r result$coefficients[2,3]` 

* The p value is 2.2e-16

* At $\alpha = 0.01$  we can reject the NULL hypothesis. 

* There is enough evidence in data to reject the possibility of no relationship between Ozone readings and temperature 


***

## Exercise 3 (Simulating Sampling Distributions)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = -5$
- $\beta_1 = 3.25$
- $\sigma^2 = 16$

We will use samples of size $n = 50$.

**(a)** Simulate this model $2000$ times. Each time use `lm()` to fit a simple linear regression model, then store the value of $\hat{\beta}_0$ and $\hat{\beta}_1$. Set a seed using **your** birthday before performing the simulation. Note, we are simulating the $x$ values once, and then they remain fixed for the remainder of the exercise.

```{r}
birthday = 12121977
set.seed(birthday)
n = 50
x = seq(0, 10, length = n)

#Function to Simulate SLR
sim_slr = function(x, beta_0 , beta_1, sigma) {
  n = length(x)
  epsilon = rnorm(n, mean = 0, sd = sigma)
  y = beta_0 + beta_1 * x + epsilon
  data.frame(predictor = x, response = y)
}

#No of simulations
m = 2000

#Initialize vector to store results
beta_hat_0 = rep(0,m)
beta_hat_1 = rep(0,m)

#Generate and store SLR coefficients 
for(i in 1:m)
{
  std_dev = 4
  df = sim_slr(x, beta_0 = -5, beta_1 = 3.25, sigma = std_dev)
  fitted_model = lm(response ~ predictor, df)
  beta_hat_0[i] = fitted_model$coefficients[1]
  beta_hat_1[i] = fitted_model$coefficients[2]
}  

```

**(b)** Create a table that summarizes the results of the simulations. The table should have two columns, one for $\hat{\beta}_0$ and one for $\hat{\beta}_1$. The table should have four rows:

- A row for the true expected value given the known values of $x$
- A row for the mean of the simulated values
- A row for the true standard deviation given the known values of $x$
- A row for the standard deviation of the simulated values

```{r}
library(knitr)

true_exp = c(-5,3.25)
sim_mean = c(mean(beta_hat_0),mean(beta_hat_1))
Sxx = sum((x- mean(x))^2)

sd_beta0 = std_dev*sqrt(1/n+ mean(x)^2/Sxx)
sd_beta1 = std_dev/sqrt(Sxx)

true_sd = c(sd_beta0,sd_beta1)

sim_sd = c(sd(beta_hat_0),sd(beta_hat_1))

table.comp  <- data.frame(rbind(true_exp, sim_mean, true_sd,sim_sd))

colnames(table.comp) = c("beta0","beta1")


```

`r kable(table.comp,"markdown",caption ="Simulation Summary")`  


**(c)** Plot two histograms side-by-side:

- A histogram of your simulated values for $\hat{\beta}_0$. Add the normal curve for the true sampling distribution of $\hat{\beta}_0$.
- A histogram of your simulated values for $\hat{\beta}_1$. Add the normal curve for the true sampling distribution of $\hat{\beta}_1$.

```{r}
#Calculate true variance of estimated beta0 and beta1
Sxx = sum((x- mean(x))^2)
true_var = 16
n= length(x)

true_sd_beta0 = sqrt(true_var*(1/n + (mean(x)^2)/Sxx))
true_sd_beta1 = sqrt(true_var/Sxx)

#Plot beta 0 estimate and true value
beta0_val = seq(from = min(beta_hat_0), to = max(beta_hat_0), by = 0.01)
beta0_density = dnorm(beta0_val, mean=-5, sd=true_sd_beta0)

par(mfrow=c(1,2))
hist(beta_hat_0,freq = FALSE)
lines(beta0_val,beta0_density, col = "red", lwd = 2)

#Plot beta 1 estimate and true value
beta1_val = seq(from = min(beta_hat_1), to = max(beta_hat_1), by = 0.01)
beta1_density = dnorm(beta1_val, mean=3.25, sd=true_sd_beta1)
hist(beta_hat_1,freq = FALSE, ylim=c(0,max(beta1_density)))

lines(beta1_val,beta1_density, col = "red", lwd = 2)


```

***

## Exercise 4 (Simulating Confidence Intervals)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = 5$
- $\beta_1 = 2$
- $\sigma^2 = 9$

We will use samples of size $n = 25$.

Our goal here is to use simulation to verify that the confidence intervals really do have their stated confidence level. Do **not** use the `confint()` function for this entire exercise.

**(a)** Simulate this model $2500$ times. Each time use `lm()` to fit a simple linear regression model, then store the value of $\hat{\beta}_1$ and $s_e$. Set a seed using **your** birthday before performing the simulation. Note, we are simulating the $x$ values once, and then they remain fixed for the remainder of the exercise.

```{r}
birthday = 12121977
set.seed(birthday)
n = 25
x = seq(0, 2.5, length = n)

#Function to Simulate SLR
sim_slr = function(x, beta_0 , beta_1, sigma) {
  n = length(x)
  epsilon = rnorm(n, mean = 0, sd = sigma)
  y = beta_0 + beta_1 * x + epsilon
  data.frame(predictor = x, response = y)
}

#No of simulations
m = 2500

#Initialize vector to store results
se = rep(0,m)
beta_hat_1 = rep(0,m)
intervals = rep(0,m)
#Generate and store SLR coefficients 
for(i in 1:m)
{
  std_dev = 3
  df = sim_slr(x, beta_0 = 5, beta_1 = 2, sigma = std_dev)
  fitted_model = lm(response ~ predictor, df)
  se[i] = summary(fitted_model)$coefficients[2,2] 
  beta_hat_1[i] = fitted_model$coefficients[2]
}  

```


**(b)** For each of the $\hat{\beta}_1$ that you simulated, calculate a 95% confidence interval. Store the lower limits in a vector `lower_95` and the upper limits in a vector `upper_95`. Some hints:

- You will need to use `qt()` to calculate the critical value, which will be the same for each interval.
- Remember that `x` is fixed, so $S_{xx}$ will be the same for each interval.
- You could, but do not need to write a `for` loop. Remember vectorized operations.


```{r}
critcal_val = qt(.025,df = n-2, lower.tail = FALSE)

lower_95 = beta_hat_1 - critcal_val*se
upper_95 = beta_hat_1 + critcal_val*se

```
**(c)** What proportion of these intervals contains the true value of $\beta_1$?

```{r}
result = mean(lower_95 <2 & upper_95>2)

```
The proportion of interval with true value is `r result`


**(d)** Based on these intervals, what proportion of the simulations would reject the test $H_0: \beta_1 = 0$ vs $H_1: \beta_1 \neq 0$ at $\alpha = 0.05$?


```{r}
result = mean(abs(beta_hat_1) > critcal_val*se  )
result
```

The proportion of simulations that would reject the test is:  `r result `

**(e)** For each of the $\hat{\beta}_1$ that you simulated, calculate a 99% confidence interval. Store the lower limits in a vector `lower_99` and the upper limits in a vector `upper_99`.

```{r}

critcal_val = qt(.005,df = n-2, lower.tail = FALSE)

lower_99 = beta_hat_1 - critcal_val*se
upper_99 = beta_hat_1 + critcal_val*se


```

**(f)** What proportion of these intervals contains the true value of $\beta_1$?

```{r}
result = mean(lower_99 <2 & upper_99>2)

```
The proportion of interval with true value is `r result`


**(g)** Based on these intervals, what proportion of the simulations would reject the test $H_0: \beta_1 = 0$ vs $H_1: \beta_1 \neq 0$ at $\alpha = 0.01$?

```{r}

result = mean(abs(beta_hat_1) > critcal_val*se  )
```

The proportion of simulations that would reject the test is:  `r result `

***

## Exercise 5 (Prediction Intervals "without" `predict`)

Write a function named `calc_pred_int` that performs calculates prediction intervals:

$$
\hat{y}(x) \pm t_{\alpha/2, n - 2} \cdot s_e\sqrt{1 + \frac{1}{n}+\frac{(x-\bar{x})^2}{S_{xx}}}.
$$

for the linear model

$$
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i.
$$

**(a)** Write this function. You may use the `predict()` function, but you may **not** supply a value for the `level` argument of `predict()`. (You can certainly use `predict()` any way you would like in order to check your work.)

The function should take three inputs:

- `model`, a model object that is the result of fitting the SLR model with `lm()`
- `newdata`, a data frame with a single observation (row)
    - This data frame will need to have a variable (column) with the same name as the data used to fit `model`.
- `level`, the level (0.90, 0.95, etc) for the interval with a default value of `0.95`

The function should return a named vector with three elements:

- `estimate`, the midpoint of the interval
- `lower`, the lower bound of the interval
- `upper`, the upper bound of the interval


```{r}
calc_pred_int <- function(cat_model, newdata1, level= .95)
{
  y_hat = predict(cat_model, newdata = newdata1)
  p_value = (1-level)/2
  #cat("pvalue", p_value, "\n")
  
  n= length(cat_model$residuals)
  #cat("n", n,"\n")
  
  se = 1.452
  #cat("se", se,"\n")
  
  critcal_val = qt(p_value, df = n-2, lower.tail = FALSE)
  #cat("critcal_val", critcal_val,"\n")
  
  x= cat_model$model[names(newdata1)][,1]
  
  x_mean = mean(x)
  #cat("x_mean", x_mean,"\n")
  
  Sxx = sum((x- mean(x))^2)
  #cat("Sxx", Sxx,"\n")
  
  #cat("new data", newdata1[,1],"\n")
 
  range = critcal_val*se*sqrt(1+1/n + (newdata1[,1] -x_mean)^2/Sxx )
  
  #cat("range", range,"\n")
  
  upper = y_hat + range
  lower = y_hat - range
  result = c(y_hat, lower,upper)
  
  #cat("upper", upper,"\n")
  #cat("lower", lower,"\n")
  
  names(result) = c("estimate","lower","upper")
  return (result)
 
}
  
  


```



**(b)** After writing the function, run this code:

```{r}
cat_model = lm(Hwt~Bwt, data = cats)
newcat_1 = data.frame(Bwt = 4.0)
calc_pred_int(cat_model, newcat_1)
```

**(c)** After writing the function, run this code:

```{r}
cat_model = lm(Hwt~Bwt, data = cats)

newcat_2 = data.frame(Bwt = 3.3)
calc_pred_int(cat_model, newcat_2, level = 0.90)
```

